import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —Ä–∞–±–æ—Ç–∞–µ–º –ª–∏ –≤ Google Colab
try:
    import google.colab
    IN_COLAB = True
    print("üöÄ –†–∞–±–æ—Ç–∞–µ–º –≤ Google Colab")
except ImportError:
    IN_COLAB = False
    print("üíª –†–∞–±–æ—Ç–∞–µ–º –ª–æ–∫–∞–ª—å–Ω–æ")

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã–º–∏ —Å–µ—Ç—è–º–∏
try:
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers, models
    from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
    from tensorflow.keras.utils import to_categorical
    print(f"‚úÖ TensorFlow {tf.__version__} –∑–∞–≥—Ä—É–∂–µ–Ω")
except ImportError:
    print("‚ùå –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ TensorFlow: pip install tensorflow")
    exit()

try:
    import cv2
    print("‚úÖ OpenCV –∑–∞–≥—Ä—É–∂–µ–Ω")
except ImportError:
    print("‚ö†Ô∏è OpenCV –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install opencv-python")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏
class Config:
    # –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
    DATA_DIR = "dataset"  # –û—Å–Ω–æ–≤–Ω–∞—è –ø–∞–ø–∫–∞ —Å –¥–∞–Ω–Ω—ã–º–∏
    EXIT_DIR = "exit"     # –ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –≤—ã—Ö–æ–¥–∞
    NOT_EXIT_DIR = "not_exit"  # –ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –Ω–µ-–≤—ã—Ö–æ–¥–∞
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    IMG_SIZE = (224, 224)  # –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    CHANNELS = 3           # RGB –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
    BATCH_SIZE = 32
    EPOCHS = 25
    VALIDATION_SPLIT = 0.2
    TEST_SPLIT = 0.2
    LEARNING_RATE = 0.001
    
    # –ò–º—è –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    MODEL_NAME = "cnn_exit_classifier.h5"

def create_sample_data():
    """–°–æ–∑–¥–∞—ë—Ç –ø—Ä–∏–º–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ (–µ—Å–ª–∏ –Ω–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞)"""
    print("üé® –°–æ–∑–¥–∞—ë–º –ø—Ä–∏–º–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏...")
    
    # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    os.makedirs(f"{Config.DATA_DIR}/{Config.EXIT_DIR}", exist_ok=True)
    os.makedirs(f"{Config.DATA_DIR}/{Config.NOT_EXIT_DIR}", exist_ok=True)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    np.random.seed(42)
    
    # "–í—ã—Ö–æ–¥—ã" - –±–æ–ª–µ–µ —è—Ä–∫–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    for i in range(100):
        img = np.random.randint(150, 255, (*Config.IMG_SIZE, Config.CHANNELS), dtype=np.uint8)
        # –î–æ–±–∞–≤–ª—è–µ–º "–¥–≤–µ—Ä–Ω–æ–π" –ø–∞—Ç—Ç–µ—Ä–Ω
        img[50:150, 80:120] = [255, 255, 255]  # –ë–µ–ª–∞—è –ø–æ–ª–æ—Å–∞ (–¥–≤–µ—Ä—å)
        plt.imsave(f"{Config.DATA_DIR}/{Config.EXIT_DIR}/exit_{i}.jpg", img)
    
    # "–ù–µ-–≤—ã—Ö–æ–¥—ã" - –±–æ–ª–µ–µ —Ç—ë–º–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    for i in range(100):
        img = np.random.randint(50, 150, (*Config.IMG_SIZE, Config.CHANNELS), dtype=np.uint8)
        plt.imsave(f"{Config.DATA_DIR}/{Config.NOT_EXIT_DIR}/not_exit_{i}.jpg", img)
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ –ø–æ 100 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")

def load_and_preprocess_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ"""
    print("üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
    exit_path = os.path.join(Config.DATA_DIR, Config.EXIT_DIR)
    not_exit_path = os.path.join(Config.DATA_DIR, Config.NOT_EXIT_DIR)
    
    if not os.path.exists(exit_path) or not os.path.exists(not_exit_path):
        print("‚ö†Ô∏è –î–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞—ë–º –ø—Ä–∏–º–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
        create_sample_data()
    
    images = []
    labels = []
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π "–≤—ã—Ö–æ–¥"
    if os.path.exists(exit_path):
        exit_files = [f for f in os.listdir(exit_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        print(f"üì∏ –ù–∞–π–¥–µ–Ω–æ {len(exit_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π '–≤—ã—Ö–æ–¥'")
        
        for filename in exit_files:
            try:
                img_path = os.path.join(exit_path, filename)
                img = load_img(img_path, target_size=Config.IMG_SIZE)
                img_array = img_to_array(img) / 255.0  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
                images.append(img_array)
                labels.append(1)  # –ú–µ—Ç–∫–∞ –¥–ª—è "–≤—ã—Ö–æ–¥"
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {filename}: {e}")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π "–Ω–µ –≤—ã—Ö–æ–¥"
    if os.path.exists(not_exit_path):
        not_exit_files = [f for f in os.listdir(not_exit_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        print(f"üì∏ –ù–∞–π–¥–µ–Ω–æ {len(not_exit_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π '–Ω–µ –≤—ã—Ö–æ–¥'")
        
        for filename in not_exit_files:
            try:
                img_path = os.path.join(not_exit_path, filename)
                img = load_img(img_path, target_size=Config.IMG_SIZE)
                img_array = img_to_array(img) / 255.0  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
                images.append(img_array)
                labels.append(0)  # –ú–µ—Ç–∫–∞ –¥–ª—è "–Ω–µ –≤—ã—Ö–æ–¥"
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {filename}: {e}")
    
    if len(images) == 0:
        raise ValueError("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!")
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy –º–∞—Å—Å–∏–≤—ã
    X = np.array(images)
    y = np.array(labels)
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(X)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {np.bincount(y)}")
    
    return X, y

def create_cnn_model():
    """–°–æ–∑–¥–∞—ë—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É CNN"""
    print("üèóÔ∏è –°–æ–∑–¥–∞—ë–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É CNN...")
    
    model = models.Sequential()
    
    # –ü–µ—Ä–≤—ã–π –±–ª–æ–∫ —Å–≤—ë—Ä—Ç–∫–∏
    model.add(layers.Conv2D(32, (3, 3), activation='relu', 
                           input_shape=(*Config.IMG_SIZE, Config.CHANNELS)))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.BatchNormalization())
    
    # –í—Ç–æ—Ä–æ–π –±–ª–æ–∫ —Å–≤—ë—Ä—Ç–∫–∏
    model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.BatchNormalization())
    
    # –¢—Ä–µ—Ç–∏–π –±–ª–æ–∫ —Å–≤—ë—Ä—Ç–∫–∏
    model.add(layers.Conv2D(128, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.BatchNormalization())
    
    # –ß–µ—Ç–≤—ë—Ä—Ç—ã–π –±–ª–æ–∫ —Å–≤—ë—Ä—Ç–∫–∏
    model.add(layers.Conv2D(256, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Dropout(0.25))
    
    # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –∏ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏
    model.add(layers.Flatten())
    model.add(layers.Dense(512, activation='relu'))
    model.add(layers.Dropout(0.5))
    model.add(layers.Dense(256, activation='relu'))
    model.add(layers.Dropout(0.3))
    
    # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π (–±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)
    model.add(layers.Dense(1, activation='sigmoid'))
    
    # –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=Config.LEARNING_RATE),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞")
    model.summary()
    
    return model

def create_data_generators():
    """–°–æ–∑–¥–∞—ë—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö —Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π"""
    print("üîÑ –°–æ–∑–¥–∞—ë–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö —Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π...")
    
    # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–ª—è –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö (—Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π)
    train_datagen = ImageDataGenerator(
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        horizontal_flip=True,
        zoom_range=0.2,
        shear_range=0.2,
        fill_mode='nearest',
        validation_split=Config.VALIDATION_SPLIT
    )
    
    # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–±–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏)
    val_datagen = ImageDataGenerator(validation_split=Config.VALIDATION_SPLIT)
    
    return train_datagen, val_datagen

def train_model(model, X_train, y_train, X_val, y_val):
    """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å"""
    print("üéØ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    
    # –ö–æ–ª–ª–±—ç–∫–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è
    callbacks = [
        keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=7,
            restore_best_weights=True,
            verbose=1
        ),
        keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.2,
            patience=5,
            min_lr=0.0001,
            verbose=1
        ),
        keras.callbacks.ModelCheckpoint(
            Config.MODEL_NAME,
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        )
    ]
    
    # –û–±—É—á–µ–Ω–∏–µ
    history = model.fit(
        X_train, y_train,
        batch_size=Config.BATCH_SIZE,
        epochs=Config.EPOCHS,
        validation_data=(X_val, y_val),
        callbacks=callbacks,
        verbose=1
    )
    
    print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    return history

def evaluate_model(model, X_test, y_test):
    """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏"""
    print("üìä –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏...")
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred_prob = model.predict(X_test)
    y_pred = (y_pred_prob > 0.5).astype(int).flatten()
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
    print(f"üéØ –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: {test_accuracy:.4f}")
    print(f"üìâ –ü–æ—Ç–µ—Ä–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: {test_loss:.4f}")
    
    # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç
    print("\nüìã –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç:")
    print(classification_report(y_test, y_pred, target_names=['–ù–µ –≤—ã—Ö–æ–¥', '–í—ã—Ö–æ–¥']))
    
    return y_pred, y_pred_prob

def visualize_results(history, y_test, y_pred):
    """–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è"""
    print("üìà –°–æ–∑–¥–∞—ë–º –≥—Ä–∞—Ñ–∏–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏
    axes[0, 0].plot(history.history['accuracy'], label='–û–±—É—á–µ–Ω–∏–µ', linewidth=2)
    axes[0, 0].plot(history.history['val_accuracy'], label='–í–∞–ª–∏–¥–∞—Ü–∏—è', linewidth=2)
    axes[0, 0].set_title('–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏', fontsize=14, fontweight='bold')
    axes[0, 0].set_xlabel('–≠–ø–æ—Ö–∞')
    axes[0, 0].set_ylabel('–¢–æ—á–Ω–æ—Å—Ç—å')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å
    axes[0, 1].plot(history.history['loss'], label='–û–±—É—á–µ–Ω–∏–µ', linewidth=2)
    axes[0, 1].plot(history.history['val_loss'], label='–í–∞–ª–∏–¥–∞—Ü–∏—è', linewidth=2)
    axes[0, 1].set_title('–ü–æ—Ç–µ—Ä–∏ –º–æ–¥–µ–ª–∏', fontsize=14, fontweight='bold')
    axes[0, 1].set_xlabel('–≠–ø–æ—Ö–∞')
    axes[0, 1].set_ylabel('–ü–æ—Ç–µ—Ä–∏')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['–ù–µ –≤—ã—Ö–æ–¥', '–í—ã—Ö–æ–¥'],
                yticklabels=['–ù–µ –≤—ã—Ö–æ–¥', '–í—ã—Ö–æ–¥'],
                ax=axes[1, 0])
    axes[1, 0].set_title('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫', fontsize=14, fontweight='bold')
    axes[1, 0].set_xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å')
    axes[1, 0].set_ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å')
    
    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    axes[1, 1].hist(y_test, bins=2, alpha=0.7, label='–ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏', color='blue')
    axes[1, 1].hist(y_pred, bins=2, alpha=0.7, label='–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è', color='red')
    axes[1, 1].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤', fontsize=14, fontweight='bold')
    axes[1, 1].set_xlabel('–ö–ª–∞—Å—Å')
    axes[1, 1].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

def predict_new_image(model, image_path):
    """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∫–ª–∞—Å—Å –¥–ª—è –Ω–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    try:
        img = load_img(image_path, target_size=Config.IMG_SIZE)
        img_array = img_to_array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        prediction = model.predict(img_array)[0][0]
        class_name = "–í—ã—Ö–æ–¥" if prediction > 0.5 else "–ù–µ –≤—ã—Ö–æ–¥"
        confidence = prediction if prediction > 0.5 else 1 - prediction
        
        print(f"üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {class_name} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%})")
        return class_name, confidence
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}")
        return None, None

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã"""
    print("üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≥—Ä–∞–º–º—ã –æ–±—É—á–µ–Ω–∏—è CNN –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–∞")
    print("=" * 60)
    
    try:
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X, y = load_and_preprocess_data()
        
        # 2. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é, –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
        X_temp, X_test, y_temp, y_test = train_test_split(
            X, y, test_size=Config.TEST_SPLIT, random_state=42, stratify=y
        )
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp, test_size=Config.VALIDATION_SPLIT/(1-Config.TEST_SPLIT), 
            random_state=42, stratify=y_temp
        )
        
        print(f"üìä –†–∞–∑–º–µ—Ä—ã –≤—ã–±–æ—Ä–æ–∫:")
        print(f"   –û–±—É—á–∞—é—â–∞—è: {len(X_train)}")
        print(f"   –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è: {len(X_val)}")
        print(f"   –¢–µ—Å—Ç–æ–≤–∞—è: {len(X_test)}")
        
        # 3. –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model = create_cnn_model()
        
        # 4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        history = train_model(model, X_train, y_train, X_val, y_val)
        
        # 5. –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
        y_pred, y_pred_prob = evaluate_model(model, X_test, y_test)
        
        # 6. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        visualize_results(history, y_test, y_pred)
        
        # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model.save(Config.MODEL_NAME)
        print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ '{Config.MODEL_NAME}'")
        
        print("\nüéâ –ü—Ä–æ–≥—Ä–∞–º–º–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print(f"üìÅ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–µ")
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–∏–¥–µ–æ
def process_video_stream(model_path, video_source=0):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
    print("üé• –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–∞...")
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        model = keras.models.load_model(model_path)
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–º–µ—Ä—É
        cap = cv2.VideoCapture(video_source)
        if not cap.isOpened():
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É")
            return
        
        print("üìπ –ù–∞–∂–º–∏—Ç–µ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞
            resized_frame = cv2.resize(frame, Config.IMG_SIZE)
            normalized_frame = resized_frame / 255.0
            input_frame = np.expand_dims(normalized_frame, axis=0)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            prediction = model.predict(input_frame, verbose=0)[0][0]
            class_name = "EXIT" if prediction > 0.5 else "NOT EXIT"
            confidence = prediction if prediction > 0.5 else 1 - prediction
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –Ω–∞ –∫–∞–¥—Ä–µ
            color = (0, 255, 0) if prediction > 0.5 else (0, 0, 255)
            cv2.putText(frame, f"{class_name}: {confidence:.2%}", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
            
            cv2.imshow('CNN Video Classification', frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()
        print("‚úÖ –í–∏–¥–µ–æ–ø–æ—Ç–æ–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ: {e}")

if __name__ == "__main__":
    main()
    
    # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–∞
    # if os.path.exists(Config.MODEL_NAME):
    #     process_video_stream(Config.MODEL_NAME)